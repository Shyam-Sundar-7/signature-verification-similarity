{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\signature verification similarity\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Desktop\\signature verification similarity\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from img2vec_pytorch import Img2Vec\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize Img2Vec with GPU\n",
    "img2vec = Img2Vec()\n",
    "\n",
    "# Read in an image (rgb format)\n",
    "img = Image.open('CEDAR/3/forgeries_3_1.png').convert('RGB')\n",
    "# Get a vector from img2vec, returned as a torch FloatTensor\n",
    "vec = img2vec.get_vec(img, tensor=True)\n",
    "# Or submit a list\n",
    "# vectors = img2vec.get_vec(list_of_PIL_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=vec.view(1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_vec(img):\n",
    "    img2vec = Img2Vec()\n",
    "    # Read in an image (rgb format)\n",
    "    img = Image.open(img).convert('RGB')\n",
    "    # Get a vector from img2vec, returned as a torch FloatTensor\n",
    "    vec = img2vec.get_vec(img, tensor=True)\n",
    "    vec=vec.view(vec.shape[0],vec.shape[1])\n",
    "    return vec.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def cosine(vec1,vec2):\n",
    "    return torch.dot(vec1,vec2)/(torch.norm(vec1)*torch.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('CEDAR_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testing_Signature</th>\n",
       "      <th>Original_Signature</th>\n",
       "      <th>Ouput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CEDAR\\47\\forgeries_47_3.png</td>\n",
       "      <td>CEDAR\\47\\original_47_6.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CEDAR\\3\\forgeries_3_9.png</td>\n",
       "      <td>CEDAR\\3\\original_3_19.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CEDAR\\54\\original_54_10.png</td>\n",
       "      <td>CEDAR\\54\\original_54_15.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CEDAR\\19\\original_19_16.png</td>\n",
       "      <td>CEDAR\\19\\original_19_20.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CEDAR\\20\\original_20_20.png</td>\n",
       "      <td>CEDAR\\20\\original_20_24.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Testing_Signature           Original_Signature  Ouput\n",
       "0  CEDAR\\47\\forgeries_47_3.png   CEDAR\\47\\original_47_6.png      0\n",
       "1    CEDAR\\3\\forgeries_3_9.png    CEDAR\\3\\original_3_19.png      0\n",
       "2  CEDAR\\54\\original_54_10.png  CEDAR\\54\\original_54_15.png      1\n",
       "3  CEDAR\\19\\original_19_16.png  CEDAR\\19\\original_19_20.png      1\n",
       "4  CEDAR\\20\\original_20_20.png  CEDAR\\20\\original_20_24.png      1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\Desktop\\signature verification similarity\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\Desktop\\signature verification similarity\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for i,j,k in zip(df['Testing_Signature'],df['Original_Signature'],df['Ouput']):\n",
    "    vec1=img_to_vec(i)\n",
    "    vec2=img_to_vec(j)\n",
    "    x.append(cosine(vec1,vec2))\n",
    "    y.append(k)\n",
    "#save as the dataframe\n",
    "df_new=pd.DataFrame({'cosine':x,'Ouput':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j,k in zip(df['Testing_Signature'],df['Original_Signature'],df['Ouput']):\n",
    "    vec1=img_to_vec(i)\n",
    "    vec2=img_to_vec(j)\n",
    "    print(cosine(vec1,vec2),k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
